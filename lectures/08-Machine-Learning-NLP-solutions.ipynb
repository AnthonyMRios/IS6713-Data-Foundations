{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python as a Calculator\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write code to load the data in the \"iris.csv\". The first 4 columns are the features. The last column is the the class. Don't forget to convert the dataset into a numpy array.\n",
    "\n",
    "After the dataset is loaded, create train and test partitions using the following scikit-learn method:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "File path: ../data/datasets/iris/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "!head ../data/datasets/iris/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = []\n",
    "y = []\n",
    "with open('../data/datasets/iris/iris.csv') as in_file:\n",
    "    iCSV = csv.reader(in_file,delimiter=',')\n",
    "    for row in iCSV:\n",
    "        X.append([float(x) for x in row[:-1]])\n",
    "        y.append(row[-1])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Using the iris data you loaded in Exercise 4, train an SVM on the train split and evaulate using accuracy on the test split. Fiddle with the parameters of the SVM to see how it effects the performance.\n",
    "\n",
    "Next, try using a different classifier, a random forest, and see how it compares to the SVM\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC F1: 0.9649122807017544 RF F1: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_svc = clf.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"SVC F1: {} RF F1: {}\".format(f1_score(y_test, y_pred_svc,average='macro'), f1_score(y_test, y_pred_rf,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Use the iris dataset then create a 2-way split (train/validation), compare all combinations loop over the SVC kernel parameters \"rbf\" and \"linear\", and C parameters 0.001, 0.01, 0.1, 1., and 10. Print the training and validation scores for every pair of parameters. How do they compare?\n",
    "\n",
    "Hint: You need to nest two for loops. You can use the train/test splits from Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001 Kernel: rbf F1: 0.1538\n",
      "C: 0.001 Kernel: linear F1: 0.5476\n",
      "C: 0.01 Kernel: rbf F1: 0.1538\n",
      "C: 0.01 Kernel: linear F1: 1.0000\n",
      "C: 0.1 Kernel: rbf F1: 1.0000\n",
      "C: 0.1 Kernel: linear F1: 0.9649\n",
      "C: 1.0 Kernel: rbf F1: 0.9649\n",
      "C: 1.0 Kernel: linear F1: 0.9649\n",
      "C: 10.0 Kernel: rbf F1: 0.9649\n",
      "C: 10.0 Kernel: linear F1: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyrios/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for C in [0.001, 0.01, 0.1, 1., 10.]:\n",
    "    for kernel in ['rbf','linear']:\n",
    "        clf = SVC(C=C, kernel=kernel)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(\"C: {} Kernel: {} F1: {:0.4f}\".format(C, kernel, f1_score(y_test, y_pred,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Use the iris dataset to create a 2-way split, but optimize the SVC parameters using GridSearchCV (also try a RandomForest model), then report the final f1 score on the test, train, and validation datasets. How close are the validation and test scores? How does the training score compare to the test and validation scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - Train F1: 0.9917645264602714 Dev F1: 0.9916666666666667 Test F1: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\":[0.0001, 0.001, 0.01, 0.1, 1., 10.], \"kernel\":[\"rbf\",\"linear\"]}\n",
    "\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, params, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_preds_svc = clf.predict(X_train)\n",
    "train_f1_svc = f1_score(y_train, train_preds_svc, average='macro')\n",
    "test_preds_svc = clf.predict(X_test)\n",
    "test_f1_svc = f1_score(y_test, test_preds_svc, average='macro')\n",
    "dev_f1_svc = clf.best_score_\n",
    "\n",
    "print(\"SVC - Train F1: {} Dev F1: {} Test F1: {}\".format(train_f1_svc, dev_f1_svc, test_f1_svc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
