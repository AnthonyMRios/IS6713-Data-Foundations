{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python as a Calculator\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write code to load the data in the \"iris.csv\" into numpy arrays.\n",
    "\n",
    "The frst 4 columns are the features/attributes. The last column is the\n",
    "class. Simply load the class as a list of strings. Don't forget to convert the\n",
    "dataset into a numpy array. You can use either DictVectorizer or the CVS\n",
    "method on the previous slide to load the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\n",
      "5.0,3.4,1.5,0.2,Iris-setosa\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "with open('../data/datasets/iris/iris.csv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Using the iris data you loaded in Exercise 1, do the following:\n",
    "\n",
    "- Use train test split() to split the iris dataset. (use 0.2 for the\n",
    "test size)\n",
    "- Train an SVM on the train split and evaluate using accuracy on the\n",
    "test split.\n",
    "- Fiddle with the parameters of the SVM to see how it effects the\n",
    "performance.\n",
    "- Calculate the accuracy on the train split. Is there a difference between the train/test accuracies?\n",
    "\n",
    "Next, try using a different classifier, a random forest, and see how it\n",
    "compares to the SVM\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Note that this is a toy dataset, so all scores will be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Using the train/test iris dataset split from exercise 2. Compare all combinations of parameters by looping over the SVC kernel parameters \"rbf\" and \"linear\",\n",
    "and C parameters 0.001, 0.01, 0.1, 1., and 10. Print the training and\n",
    "validation scores for every pair of parameters.\n",
    "\n",
    "\n",
    "Hint: You need to nest two for loops. You can use the train/test splits from Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Use the iris dataset to create a 3-way split (train/val/test), optimize the SVC parameters using the validation split, then report the final f1 score on the test, train, and validation datasets.\n",
    "\n",
    "You will need to use the train\\_test\\_split() method on the train dataset from Exercise 2. You can use a 10% test size.\n",
    "\n",
    "How close are the validation and test scores? How does the training score compare to the test and validation scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Project\n",
    "\n",
    "For this exercise, you will code your own k nearest neighbor method. For this assume \"k\" is equal to 1. You can use euclidean distance to find similar examples.\n",
    "\n",
    "Euclidean distance is defined as\n",
    "\n",
    "$ EDist = \\sqrt{(x_0 - v_0)^2 + (x_1 - v_1)^2 + \\dots + (x_{D-1} - v_{D-1})^2} $\n",
    "\n",
    "where D is the dimension size (number of elements) for the vectors.\n",
    "\n",
    "**Hint:** The **easiest** way to complete this exercise is with for loops. The **fastest** way to complete this exercise is to complete this exericse is to use numpy cleverness. Both approaches are acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(query, X, y):\n",
    "    '''\n",
    "        Complete this function to return the class of the closest\n",
    "        example (row) in X to the vector \"query\" based on euclidean\n",
    "        distance.\n",
    "        :param vector query: A numpy vector (Will be one row from the test set from Exercise 2)\n",
    "        :param matrix X: A numpy matrix (will be training dataset from Exercise 2)\n",
    "        :return: Return the class (element of y) corresponding the the closes item in X to query.\n",
    "    '''\n",
    "    # Write code to complete this function here.\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code that loops over each text row and makes a prediction using the kNN method above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "The tab (\\t) separated file \"sentiment-twitter-data.tsv\" contains tweets annotated for sentiment. Load the data then do the following:\n",
    "\n",
    "- split the dataset into a train/test split.\n",
    "- create a bag of words feature representation for the tweets using the CountVectorizer\n",
    "- Use grid-search (CV) on the train split to find the best C parameters for a LinearSVC classifier. Only test 2 C values to reduce overhead (0.1 and 1.). Also, use a 2-fold CV, i.e., cv=2.\n",
    "- report (print) the accuracy of the final classifier on the test data and train data\n",
    "- How many features were created with the bag of words representation?\n",
    "\n",
    "file path: ../data/sentiment-twitter-data.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264183816548130816\t15140428\tpositive\tGas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\n",
      "264249301910310912\t18516728\tnegative\tIranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\n",
      "264105751826538497\t147088367\tpositive\twith J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.\n",
      "264094586689953794\t332474633\tnegative\tTalking about ACT's &amp;&amp; SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\n",
      "254941790757601280\t557103111\tnegative\tThey may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\n",
      "264169034155696130\t382403760\tneutral\tIm bringing the monster load of candy tomorrow, I just hope it doesn't get all squiched\n",
      "263192091700654080\t344222239\tobjective-OR-neutral\tApple software, retail chiefs out in overhaul: SAN FRANCISCO Apple Inc CEO Tim Cook on Monday replaced the heads... http://t.co/X49ZEOsG\n",
      "263398998675693568\t812957996\tpositive\t@oluoch @victor_otti @kunjand I just watched it! Sridevi's comeback.... U remember her from the 90s?? Sun mornings on NTA ;)\n",
      "260200142420992000\t332530284\tobjective\t#Livewire Nadal confirmed for Mexican Open in February: Rafael Nadal is set to play at the Me... http://t.co/zgUXpcnC #LiveWireAthletics\n",
      "264087629237202944\t61903760\tpositive\t@MsSheLahY I didnt want to just pop up... but yep we have chapel hill next wednesday you should come.. and shes great ill tell her you asked\n"
     ]
    }
   ],
   "source": [
    "# This is a tab seperated file, so with csv reader use delimiter=\"\\t\"\n",
    "with open('../data/sentiment-twitter-data.tsv') as in_file:\n",
    "    count = 0\n",
    "    for row in in_file:\n",
    "        print(row.strip())\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
