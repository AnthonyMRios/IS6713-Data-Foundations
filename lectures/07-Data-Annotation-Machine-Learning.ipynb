{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python as a Calculator\n",
    "\n",
    "Blank notebook to be used for class exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write code to calculate and print the cohen's kappa between rater1 and rater2.\n",
    "\n",
    "Hint: You will need to create the confusion matrix (matrix of how many times each rater agrees for each item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater1 = ['yes','no','yes','yes','yes','yes','no','yes','yes']\n",
    "rater2 = ['yes','no','no','yes','yes','yes','yes','yes','yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Using the file \"twitter-inclass-annotations-easy.csv\" write code to calculate agreement using the Fleiss' kappa.\n",
    "\n",
    "Each column of the file represents classes, and the rows represent the tweet. The numbers - except for the tweet id - represent the number of students who agreed for that specific tweet on that class.\n",
    "\n",
    "File path: ../data/twitter-inclass-annotations-easy.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = open('../data/twitter-inclass-annotations-easy.csv')\n",
    "t = []\n",
    "for i in a:\n",
    "    t.append(i[1:])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Write code to load the data in the \"iris.csv\". The first 4 columns are the features. The last column is the the class. Don't forget to convert the dataset into a numpy array.\n",
    "\n",
    "After the dataset is loaded, create train and test partitions using the following scikit-learn method:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "File path: ../data/datasets/iris/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Using the iris data you loaded in Exercise 4, train an SVM on the train split and evaulate using accuracy on the test split. Fiddle with the parameters of the SVM to see how it effects the performance.\n",
    "\n",
    "Next, try using a different classifier, a random forest, and see how it compares to the SVM\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
